# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W0O0udCCzMdO31kX-I_JyVATQfXWgPd8
"""
from flask import Flask, render_template, request, jsonify
import keras
from keras.models import Sequential, load_model
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D, BatchNormalization
from keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ReduceLROnPlateau, LearningRateScheduler
from keras.utils import to_categorical
from keras.layers import Embedding, Input, dot, concatenate
from keras.models import Model
from IPython.display import SVG
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from keras.models import Model
from keras.layers import Input, Reshape, Dot
from keras.layers import Embedding
from keras.regularizers import l2
import pandas as pd
import matplotlib
from pandas import Series, DataFrame
import time
from sklearn.model_selection import train_test_split
from functools import reduce
import random

def pre_process_df(filename):
    """
    This function removes the duplicated rows
                  removes product with prices <= 0 (might be coupons, gifts, or refunds)
                  removes products with missing brand information.
    @Input: filename (string): path to file
    @Output: df (Pandas DataFrame)
    """
    if filename:
        df = pd.read_csv(filename)
        df = df.drop_duplicates()
        #df = df[df.brand.notnull()]
        return df[df.price > 0]
    return None

def gen_purchase_count(files):
    """
    This function generates the train data (user-brand purchase history).
    @Output: df (Pandas DataFrmae). Each entry indicates the purchase count.
    """
    df = pd.concat([pre_process_df(f) for f in files])
    df = df.loc[:, ['event_type', 'product_id', 'user_id']]
    df['purchase_count'] = [1 if e == 'purchase' else 0 for e in df['event_type']]
    df = df.drop(['event_type'], axis = 1)
    df = df.groupby(['product_id', 'user_id']).sum()
    df = df[df.purchase_count != 0]
    return df.reset_index()

# file1='merged_data_no_duplicates.csv'
file2='data.csv'
# file3='2020-Jan.csv/2020-Jan.csv'
# file4='2020-Feb.csv/2020-Feb.csv'
purchase_count = gen_purchase_count([file2])

user_id  = np.unique(purchase_count['user_id'])
num_product_purchased = np.zeros(len(user_id))
for loc, user in enumerate(user_id):
    num_product_purchased[loc] = np.sum(purchase_count['user_id'] == user)

idx = np.where(num_product_purchased>=10)

filitered_user_id = user_id[idx]

df = purchase_count.loc[purchase_count['user_id'].isin(filitered_user_id)]



user_enc = LabelEncoder()
df['user_id'] = user_enc.fit_transform(df['user_id'].values)
n_users = df['user_id'].nunique()
item_enc = LabelEncoder()
df['product_id'] = item_enc.fit_transform(df['product_id'].values)
n_products = df['product_id'].nunique()
df['purchase_count'] = df['purchase_count'].values.astype(np.float32)
min_cnt = min(df['purchase_count'])
max_cnt = max(df['purchase_count'])
# n_users, n_products , min_cnt, max_cnt

X = df[['user_id', 'product_id']].values
Y = df['purchase_count'].values

from sklearn.model_selection import train_test_split
x_train1, x_test, y_train1, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)
x_train, x_val, y_train, y_val = train_test_split(x_train1, y_train1, test_size = 0.2, random_state = 42)

num_latent_factors = 30

X_train_array = [x_train[:, 0], x_train[:, 1]]
X_test_array = [x_test[:, 0], x_test[:, 1]]

def RecommenderV1(n_users, n_products, n_factors):
    user = Input(shape=(1,))
    u = Embedding(n_users, n_factors, embeddings_initializer='he_normal',
                  embeddings_regularizer=l2(1e-6))(user)
    u = Reshape((n_factors,))(u)

    product = Input(shape=(1,))
    m = Embedding(n_products, n_factors, embeddings_initializer='he_normal',
                  embeddings_regularizer=l2(1e-6))(product)
    m = Reshape((n_factors,))(m)

    x = Dot(axes=1)([u, m])
    model = Model(inputs=[user, product], outputs=x)
    opt = Adam(lr=0.001)
    model.compile(loss='mean_squared_error', optimizer=opt, metrics = ['acc'])
    return model

n_factors = 30
model = RecommenderV1(n_users, n_products, n_factors)
model.summary()

history=model.fit(x=X_train_array, y=y_train, batch_size=2048, epochs=30, verbose=1,
                    validation_data=(X_test_array, y_test))

# model.save('model.h5')

training_loss = history.history['loss']
test_loss = history.history['val_loss']

# Create count of the number of epochs
epoch_count = range(1, len(training_loss) + 1)

# Visualize loss history
plt.figure(figsize = (8,4))
plt.plot(epoch_count, training_loss, 'r--')
plt.plot(epoch_count, test_loss, 'b-')
plt.legend(['Training Loss', 'Val Loss'])
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.show()
# plt.savefig('loss-epoch.png')



print(model.evaluate(X_test_array, y_test,verbose=0))

print(len(X_test_array[0]))

y_pred = model.predict(X_test_array)


def precisionatk(y_true,y_pred, k):
    precision_average = []
    idx =  (-y_pred).argsort(axis=-1)[:,:k] ###k
    for i in range(idx.shape[0]):
        precision_sample = 0
        for j in idx[i,:]:
            if y_true[j] > 0:
                precision_sample += 1
        precision_sample = precision_sample / k
        precision_average.append(precision_sample)
    return np.mean(precision_average)

pre_k2 = []
for k in range(2, 31):
    pre = precisionatk(y_test, y_pred, k)
    pre_k2.append(pre)

print(np.mean(pre_k2))

import matplotlib.pyplot as plt

plt.plot(range(2, 31), pre_k2)
plt.xlabel('k')
plt.ylabel('precision@K')
plt.show()
# plt.savefig('precison@k.png')


# # 1. Encode User ID
# target_user_id=576802932
# target_user_encoded = user_enc.transform([target_user_id])[0]

# # 2. Generate Candidate Products
# candidate_product_ids = np.arange(n_products)

# # 3. Predict Purchase Counts
# predicted_purchase_counts = model.predict([np.array([target_user_encoded] * n_products), candidate_product_ids])

# # 4. Sort Recommendations
# recommended_product_indices = np.argsort(predicted_purchase_counts, axis=0)[::-1]

# # 5. Decode Product IDs
# recommended_product_ids = item_enc.inverse_transform(candidate_product_ids[recommended_product_indices])

# # Print the top recommended products
# num_recommendations = 10  # You can change this value
# top_recommendations = recommended_product_ids[:num_recommendations]
# print("Top", num_recommendations, "Recommended Products:")
# for product_id in top_recommendations:
#     print("Product ID:", product_id)
