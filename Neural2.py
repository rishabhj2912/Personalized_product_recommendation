# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f-NXLMSleKrfUbLBRqh9bfVfvlASYNK4
"""

import keras
from keras.models import Sequential, load_model
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D, BatchNormalization
from keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ReduceLROnPlateau, LearningRateScheduler
from keras.utils import to_categorical
from keras.layers import Embedding, Input, dot, concatenate
from keras.models import Model
from IPython.display import SVG
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from keras.models import Model
from keras.layers import Input, Reshape, Dot
from keras.layers import Embedding
from keras.regularizers import l2
import pandas as pd
import matplotlib
from pandas import Series, DataFrame
import time
from sklearn.model_selection import train_test_split
from functools import reduce
import random

def pre_process_df(filename):
    """
    This function removes the duplicated rows
                  removes product with prices <= 0 (might be coupons, gifts, or refunds)
                  removes products with missing brand information.
    @Input: filename (string): path to file
    @Output: df (Pandas DataFrame)
    """
    if filename:
        df = pd.read_csv(filename)
        df = df.drop_duplicates()
        df = df[df.brand.notnull()]
        return df[df.price > 0]
    return None

def gen_purchase_count(files):
    """
    This function generates the train data (user-brand purchase history).
    @Output: df (Pandas DataFrmae). Each entry indicates the purchase count.
    """
    df = pd.concat([pre_process_df(f) for f in files])
    df = df.loc[:, ['event_type', 'brand_id', 'user_id']]
    df['purchase_count'] = [1 if e == 'purchase' else 0 for e in df['event_type']]
    df = df.drop(['event_type'], axis = 1)
    df = df.groupby(['brand_id', 'user_id']).sum()
    df = df[df.purchase_count != 0]
    return df.reset_index()

file1='data.csv'
# file2='/content/2019-Dec.csv'
# file3='/content/2020-Jan.csv'
# file4='/content/2020-Feb.csv'
purchase_count = gen_purchase_count([file1])

user_id  = np.unique(purchase_count['user_id'])
num_brand_purchased = np.zeros(len(user_id))
for loc, user in enumerate(user_id):
    num_brand_purchased[loc] = np.sum(purchase_count['user_id'] == user)

idx = np.where(num_brand_purchased>=5)
filitered_user_id = user_id[idx]
df2 = purchase_count.loc[purchase_count['user_id'].isin(filitered_user_id)]

user_enc2 = LabelEncoder()
df2['user_id'] = user_enc2.fit_transform(df2['user_id'].values)
n_users = df2['user_id'].nunique()
brand_enc = LabelEncoder()
df2['brand_id'] = brand_enc.fit_transform(df2['brand_id'].values)
n_brands = df2['brand_id'].nunique()
df2['cnt'] = df2['purchase_count'].values.astype(np.float32)
min_cnt = min(df2['purchase_count'])
max_cnt = max(df2['purchase_count'])
# n_users, n_brands , min_cnt, max_cnt

X = df2[['user_id', 'brand_id']].values
Y = df2['purchase_count'].values

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)

# x_train.shape, x_test.shape, y_train.shape, y_test.shape

num_latent_factors = 30

X_train_array = [x_train[:, 0], x_train[:, 1]]
X_test_array = [x_test[:, 0], x_test[:, 1]]

def RecommenderV1(n_users, n_products, n_factors):
    user = Input(shape=(1,))
    u = Embedding(n_users, n_factors, embeddings_initializer='he_normal',
                  embeddings_regularizer=l2(1e-6))(user)
    u = Reshape((n_factors,))(u)

    product = Input(shape=(1,))
    m = Embedding(n_products, n_factors, embeddings_initializer='he_normal',
                  embeddings_regularizer=l2(1e-6))(product)
    m = Reshape((n_factors,))(m)

    x = Dot(axes=1)([u, m])
    model2 = Model(inputs=[user, product], outputs=x)
    opt = Adam(lr=0.001)
    model2.compile(loss='mean_squared_error', optimizer=opt, metrics = ['acc'])
    return model2

n_factors = 30
model2 = RecommenderV1(n_users, n_brands, n_factors)
print(model2.summary())

history = model2.fit(x=X_train_array, y=y_train, batch_size=16384, epochs=20, verbose=1,
                    validation_data=(X_test_array, y_test))

# model2.save('model2.h5')

training_loss = history.history['loss']
test_loss = history.history['val_loss']

# Create count of the number of epochs
epoch_count = range(1, len(training_loss) + 1)

# Visualize loss history
plt.figure(figsize = (8,4))
plt.plot(epoch_count, training_loss, 'r--')
plt.plot(epoch_count, test_loss, 'b-')
plt.legend(['Training Loss', 'Test Loss'])
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.show()
# plt.savefig('loss-epoch-model2.png')

print(model2.evaluate(X_test_array, y_test,verbose=0))

y_pred = model2.predict(X_test_array)



target_user_id=576802932
target_user_enc2oded = user_enc2.transform([target_user_id])[0]

# 2. Generate Candidate Products
candidate_brand_ids = np.arange(n_brands)

# 3. Predict Purchase Counts
predicted_purchase_counts = model2.predict([np.array([target_user_enc2oded] * n_brands), candidate_brand_ids])

# 4. Sort Recommendations
recommended_product_indices = np.argsort(predicted_purchase_counts, axis=0)[::-1]

# 5. Decode Product IDs
recommended_product_ids = brand_enc.inverse_transform(candidate_brand_ids[recommended_product_indices])

# Print the top recommended products
num_recommendations = 10  # You can change this value
top_recommendations = recommended_product_ids[:num_recommendations]
print("Top", num_recommendations, "Recommended Brands:")
for product_id in top_recommendations:
    print("Brand ID:", product_id)

def precisionatk(y_true,y_pred, k):
    precision_average = []
    idx =  (-y_pred).argsort(axis=-1)[:,:k] ###k
    for i in range(idx.shape[0]):
        precision_sample = 0
        for j in idx[i,:]:
            if y_true[j] > 0:
                precision_sample += 1
        precision_sample = precision_sample / k
        precision_average.append(precision_sample)
    return np.mean(precision_average)

pre_k2 = []
for k in range(2, 31):
    pre = precisionatk(y_test, y_pred, k)
    pre_k2.append(pre)

np.mean(pre_k2)

import matplotlib.pyplot as plt

plt.plot(range(2, 31), pre_k2)
plt.xlabel('k')
plt.ylabel('precision@K')
plt.show()
# plt.savefig('precision@k-model2.png')